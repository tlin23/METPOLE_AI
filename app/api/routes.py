"""
API routes for the application.
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional, Dict, Any

from app.crawler.crawl import crawl
from app.embedder.embed import Embedder
from app.retriever.ask import Retriever


# Create router
router = APIRouter()

# Initialize components
embedder = Embedder()
retriever = Retriever()


# Define models
class CrawlRequest(BaseModel):
    url: str


class CrawlResponse(BaseModel):
    url: str
    content: Optional[str] = None
    doc_id: Optional[str] = None
    success: bool
    message: str


class QueryRequest(BaseModel):
    query: str
    n_results: Optional[int] = 5


class QueryResponse(BaseModel):
    query: str
    results: List
    success: bool
    message: str


class AskRequest(BaseModel):
    question: str
    top_k: Optional[int] = 5


class ChunkResult(BaseModel):
    text: str
    metadata: Optional[Dict[str, Any]] = None
    distance: Optional[float] = None


class AskResponse(BaseModel):
    question: str
    chunks: List[ChunkResult]
    answer: Optional[str] = None
    success: bool
    message: str


@router.post("/crawl", response_model=CrawlResponse)
async def crawl_url(request: CrawlRequest):
    """
    Crawl a URL and store its content.
    """
    try:
        # Crawl the URL
        content, metadata = crawl(request.url)
        
        if not content:
            return CrawlResponse(
                url=request.url,
                success=False,
                message="Failed to extract content from URL"
            )
        
        # Embed the content with metadata
        doc_id = embedder.embed_text(content, metadata=metadata)
        
        return CrawlResponse(
            url=request.url,
            content=content[:100] + "..." if len(content) > 100 else content,
            doc_id=doc_id,
            success=True,
            message="URL crawled and embedded successfully"
        )
    
    except Exception as e:
        return CrawlResponse(
            url=request.url,
            success=False,
            message=f"Error: {str(e)}"
        )


@router.post("/query", response_model=QueryResponse)
async def query_data(request: QueryRequest):
    """
    Query the embedded data.
    """
    try:
        results = retriever.query(request.query, request.n_results)
        
        return QueryResponse(
            query=request.query,
            results=results,
            success=True,
            message="Query executed successfully"
        )
    
    except Exception as e:
        return QueryResponse(
            query=request.query,
            results=[],
            success=False,
            message=f"Error: {str(e)}"
        )


@router.post("/ask", response_model=AskResponse)
async def ask_question(request: AskRequest):
    """
    Ask a question and get an answer generated by OpenAI's GPT model based on the most relevant chunks.
    
    Returns the model's answer along with the top-k most relevant chunks used to generate the answer.
    """
    try:
        # Query the vector store using cosine similarity
        results = retriever.query(request.question, request.top_k)
        
        # Format the results
        chunks = []
        for i in range(len(results["documents"][0])):
            chunk = ChunkResult(
                text=results["documents"][0][i],
                metadata=results["metadatas"][0][i] if "metadatas" in results and results["metadatas"][0] else None,
                distance=results["distances"][0][i] if "distances" in results and results["distances"][0] else None
            )
            chunks.append(chunk)
        
        # Generate an answer using OpenAI's GPT model
        answer = retriever.generate_answer(request.question, chunks)
        
        return AskResponse(
            question=request.question,
            chunks=chunks,
            answer=answer,
            success=True,
            message="Question answered successfully with AI-generated response"
        )
    
    except Exception as e:
        return AskResponse(
            question=request.question,
            chunks=[],
            success=False,
            message=f"Error: {str(e)}"
        )
