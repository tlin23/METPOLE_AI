"""
API routes for the application.
"""

from fastapi import APIRouter

from app.api.models import AskRequest, ChunkResult, AskResponse
from app.retriever.ask import Retriever

# Create router
router = APIRouter()

# Initialize components
retriever = Retriever()


@router.post("/ask", response_model=AskResponse)
async def ask_question(request: AskRequest):
    """
    Ask a question and get an answer generated by OpenAI's GPT model based on the most relevant chunks.

    Returns the model's answer along with the top-k most relevant chunks used to generate the answer.
    The response includes:
    - The answer text with appropriate disclaimers if applicable
    - Flags indicating if the answer is based on general knowledge or contains DIY advice
    - Source information tracing the chunks used to generate the answer
    - The chunks themselves with their metadata
    """
    try:
        # Query the vector store using cosine similarity
        results = retriever.query(request.question, request.top_k)

        # Format the results
        chunks = []
        for i in range(len(results["documents"][0])):
            chunk = ChunkResult(
                text=results["documents"][0][i],
                metadata=(
                    results["metadatas"][0][i]
                    if "metadatas" in results and results["metadatas"][0]
                    else None
                ),
                distance=(
                    results["distances"][0][i]
                    if "distances" in results and results["distances"][0]
                    else None
                ),
            )
            chunks.append(chunk)

        # Generate an answer using OpenAI's GPT model
        answer_result = retriever.generate_answer(request.question, chunks)

        return AskResponse(
            question=request.question,
            chunks=chunks,
            answer=answer_result["answer"],
            is_general_knowledge=answer_result["is_general_knowledge"],
            contains_diy_advice=answer_result["contains_diy_advice"],
            source_info=answer_result["source_info"],
            success=True,
            message="Question answered successfully with AI-generated response",
            prompt=answer_result["prompt"],
        )

    except Exception as e:
        return AskResponse(
            question=request.question,
            chunks=[],
            success=False,
            message=f"Error: {str(e)}",
        )
