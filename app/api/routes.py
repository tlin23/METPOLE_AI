"""
API routes for the application.
"""

import os
import sys
from fastapi import APIRouter
from pydantic import BaseModel
from typing import List, Optional, Dict, Any

from app.retriever.ask import Retriever


# Add the project root to the Python path to allow importing from data/processed
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

# Create router
router = APIRouter()

# Initialize components
retriever = Retriever()


# Define models
class AskRequest(BaseModel):
    question: str
    top_k: Optional[int] = 5


class ChunkResult(BaseModel):
    text: str
    metadata: Optional[Dict[str, Any]] = None
    distance: Optional[float] = None


class AskResponse(BaseModel):
    question: str
    chunks: List[ChunkResult]
    answer: Optional[str] = None
    is_general_knowledge: Optional[bool] = False
    contains_diy_advice: Optional[bool] = False
    source_info: Optional[str] = None
    success: bool
    message: str


@router.post("/ask", response_model=AskResponse)
async def ask_question(request: AskRequest):
    """
    Ask a question and get an answer generated by OpenAI's GPT model based on the most relevant chunks.

    Returns the model's answer along with the top-k most relevant chunks used to generate the answer.
    The response includes:
    - The answer text with appropriate disclaimers if applicable
    - Flags indicating if the answer is based on general knowledge or contains DIY advice
    - Source information tracing the chunks used to generate the answer
    - The chunks themselves with their metadata
    """
    try:
        # Query the vector store using cosine similarity
        results = retriever.query(request.question, request.top_k)

        # Format the results
        chunks = []
        for i in range(len(results["documents"][0])):
            chunk = ChunkResult(
                text=results["documents"][0][i],
                metadata=(
                    results["metadatas"][0][i]
                    if "metadatas" in results and results["metadatas"][0]
                    else None
                ),
                distance=(
                    results["distances"][0][i]
                    if "distances" in results and results["distances"][0]
                    else None
                ),
            )
            chunks.append(chunk)

        # Generate an answer using OpenAI's GPT model
        answer_result = retriever.generate_answer(request.question, chunks)

        return AskResponse(
            question=request.question,
            chunks=chunks,
            answer=answer_result["answer"],
            is_general_knowledge=answer_result["is_general_knowledge"],
            contains_diy_advice=answer_result["contains_diy_advice"],
            source_info=answer_result["source_info"],
            success=True,
            message="Question answered successfully with AI-generated response",
        )

    except Exception as e:
        return AskResponse(
            question=request.question,
            chunks=[],
            success=False,
            message=f"Error: {str(e)}",
        )
